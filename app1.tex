%\subsection{Récupération de l'image du corps humain}
%SDK de la kinect avec skelette
%\subsection{Préparation de l'image}
%suppression du bruit et diminution du nombre de point -> pcl
%\subsection{Segmentation du corps humain}
%distance geodesic avec dikjstra -> pb nombre de voisin
%superpixel
%\subsection{Reconnaissance des parties du corps}
%descripteur D2 avec model 3D
%FPFH
%\subsection{Appariement d'un model 3D}
%scale à partir d'une bounding box
%ICP
%moment d'inertie
%\subsection{Résultat des expérimentations}
%montrer plusieurs images de la segmentation et montrer ce qui ne convient pas
%dire que les méthode utilisé seront utilisé dans la suite du projet 
\subsection{Objectif}
%on cherche a ne pas utiliser la kinect
Cette première application a plusieurs objectifs. Dans un premier temps, nous souhaitons réaliser 
une segmentation sans utiliser les outils fournis pas la Kinect dans le but d'obtenir une méthode plus
précise ou tout du moins permettant d'améliorer une partie du procédé de segmentation. Comme nous l'avons vu dans 
l'état de l'art, les méthodes utilisées par la Kinect ont évolué et sont devenu plus stable et plus précise.
Le second objectif et de remplacer un nuage de point représentant un membre par un modèle 3D de ce même membre
mais ayant une forme différente. Cette première partie du stage me permet surtout d'aborder des concepts qui me 
serviront dans la second application qui est le but premier de ce stage.

\subsection{Délimitation du corps humain et minimisation de la quantité de donnée}
%prétraitement
%utilisation voxel pour réduire le nombre de point
%utilisation d'outils pour supprimer les outlier
%utilisation de threshold
%suppression d'objet à la main
%utilisateur peut les modifier lui meme
%finalement utilisation de la Kinect pour la delimitation
Durant cette première phase nous travaillons sur un nuage de point et non sur les informations de l'image de profondeur.
Comme nous l'avons dit précédemment, l'ensemble des informations n'est pas pértinente pour les traitements que nous souhaitons
réaliser. Dans cette première application il nous faut dabord supprimer l'ensemble des informations qui ne se rapporte pas 
au corps humain. La première solution que j'ai utilisé et qui était la plus simple a été de mettre deux seuil afin de 
supprimer les informations qui sont au-dessus d'un certain seuil ainsi que les informations qui sont en-dessous d'un second
seuil. Ces seuils sont les distances, en mètre, dans lequel l'utilisateur doit se trouver. Cette méthode est utilisé dans 
l'application ReconstructMe\footnote{http://reconstructme.net} qui est une application permettant de construire un modèle
3D complet à partir de données fournit par plusieurs images provenant d'une caméra 3D. Comme pour cette application, j'ai
décidé de laisser la possibilité à l'utilisateur de changer les seuils en fonction de sont besoin.\\

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[width=8cm]{image/seuil1.PNG}
    \caption{Résultat d'une segmentation par seuillage}
    \label{fig:seuillage}
  \end{center}
\end{figure}

Nous pouvons voir sur la Fig. \ref{fig:seuillage} que le seuil permet effectivement de supprimer beaucoup d'information
correspondant à l'environnement, mais qu'il reste beaucoup de bruit du à la qualité de l'acquisition de la caméra. La librairie
PCL\cite{PCL} nous fournit beaucoup d'outil pour ce genre de problèmatique. Il y a une classe appelé StatisticalOutlierRemoval
qui permet de supprimer les points supposé être du bruit. Pour cela cette classe calcul la distance moyenne d'un point avec son
voisinnage et si cette moyenne est trop élevé, elle supprime le point en question.\\

%TODO mettre une image délimitant le corps humain avec des seuils et avec la suppression du bruit
% \begin{figure}[!ht]
%   \begin{center}
%     \includegraphics[width=5cm]{image/wait.png}
%     \caption{Résultat d'une segmentation par seuillage avec suppression du bruit}
%     \label{fig:seuillageOutlier}
%   \end{center}
% \end{figure}

Pour la suite des traitements que nous souhaitons réalisé, il est préférable d'avoir un minimum d'information et de ne garder
que ce qui est pertinant. Le corps humain que nous avons réussi à délimité comporte encore beaucoup trop de données. Le nombre
de point fournit par la Kinect est très important et très concentré, il est possible de supprimer des points qui sont trop 
proche les uns les autres. La encore PCL\cite{PCL} peut nous aider avec la classe VoxelGrid. Cette classe crée une grille de
voxel sur le nuage de point dont la taille est définit par l'utilisateur. L'ensemble des points à l'intérieur d'un voxel sont 
approximé en un point qui correspond au centroïde du voxel. Grâce à l'ensemble de ces traitements nous ne gardons que l'information 
essentiel à nos traitement.

\subsection{Calcule de la distance géodésique}
Ma première idée pour segmenter le corps humain est d'utiliser la distance géodesique. Y. Liu et al\cite{GIF} montre que la distance
géodesique pour une même personne quelque soit sa posture est toujours la même pour les points de ces membres. Le seul problème 
est que plusieurs membres ont la même distance géodésique, on ne peut donc pas associer un membre à une distance directement.
Cependant, s'il est possible de seuiller le corps et d'en calculer des descripteurs, nous pourrons déterminer quel nuage de point
correspond à quel membre.\\

Avant de calculer la distance géodésique du corps humain, nous avons besoin de créer un maillage sur le nuage de point. Pour cela
j'ai repris le principe utilisé pour le descripteur FPFH\cite{FPFH} pour la sélection des voisins. Dans un premier temps je calcule
la distance euclidienne de chacun des points du nuage de point avec tous les autres. Pour la création du voisinage je considère non
seulement le nombre maximum de point à prendre en compte, mais aussi la distance maximum d'un point avec les autres. Nous avons eu
plusieurs problème lorsque nous n'avions pas mis la second condition, car lorsque la main de l'utilisateur était trop proche de sa 
jambe certain point de la main avait des voisins dans la jambe.\\

%TODO voir si on met des exemples de maillage defectueux 

A cette étape de l'algorithme nous avons donc un maillage et les distances euclidiennes de chaque point avec son voisinnage. Pour calculer
la distance géodésique du centroïde du nage de point avec chaque point nous allons utilisé l'algorithme de Dijkstra\cite{dijkstra}.
Il faut donc trouver le plus court chemin du centroïde jusqu'au point dont on veut calculer la distance géodésique en passant par le
maillage que nous avons construit précédemment. A chaque fois qu'un point est ajouté au chemin emprunté par l'algorithme il faut 
additionner la distance euclidienne entre ce point et le précédent pour obtenir un résultat final correspondant à la distance 
géodésique.\\

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[width=5cm]{image/cheminGeodesique.PNG}
    \caption{Exemple de chemin parcouru par l'algorithme de calcul de la distance géodésique pour un point.
    Le point vert correspond au centre de gravité du corps, les points rouge sont les noeuds du chemin et le point 
    orange est le point d'arrivé. Les chiffres jaune sont les distances pour allez d'un noeud à l'autre et les chiffres
    rouge est la distance géodésique au noeud correspondant.}
    \label{fig:cheminGeodesique}
  \end{center}
\end{figure}

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[width=6.5cm]{image/geodesic1.PNG}
    \includegraphics[width=6cm]{image/geodesic2.PNG}
    \caption{Résultat du calcul de la distance géodésique sur l'ensemble du nuage de point. Le point vert correspond au centroïde du
    nuage de point. Plus la couleur des points est proche de rouge, plus les points sont proches du centroïde.}
    \label{fig:geodesique}
  \end{center}
\end{figure}

Sur les images de la Fig. \ref{fig:geodesique} on peut voir que la distance géodésique n'est pas aussi précise qu'on le souhaiterait.
Dans la première image on voit que la distance géodésique n'est pas la même sur le bras gauche et sur le bras droit. Cette imprécision
vient de la qualité du maillage, certains points ne passent pas par le corps et traverse dans le vide du ventre au bras, ce qui réduit
la distance géodésique au niveau des mains. Dans la second image, on voit que la position du centroïde est très importante, la position
du centroïde change en fonction de ce que l'on voit du corps humain, ce qui modifie également la distance géodésique. Un simple seuillage
n'est donc pas suffisant pour segmenter le corps humain.

\subsection{Segmentation du corps humain}
%recherche du point le plus éloigné puis suppression d'un groupe de point ....
%voir si on parle des superpixels
Malgrès un léger manque de précision de la par du calcul de la distance géodésique sur le corps humain, nous avons testé une
méthode de segmentation qui ne prend pas en compte cette imprécision. Le principe de cette segmentation est de détecter le
membre le plus éloigné puis de le supprimer dans la recherche des autres membres. Pour cela, notre algorithme recherche le point
dont la distance géodésique est la plus grande et forme une zone autour de ce point. Cette zone a un rayon prédéfini qui sera le 
même pour chaque membre. Elle sera enregistré en mémoire et les points de cette zone seront supprimé du nuage de point du corps humain dans
lequel nous effectuons notre recherche.\\

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[width=3cm]{image/humanFootR.png}
    \includegraphics[width=3cm]{image/humanFootL.png}
    \includegraphics[width=3cm]{image/humanHandR.png}
    \includegraphics[width=3cm]{image/humanHandL.png}
    \caption{Premières étape de l'algorithme de segmentation du corps humain. Le point vert correspond au point le plus éloigné et la zone rouge
    l'ensemble des points concidérés comme fesant partie du membre.}
    \label{fig:geodesique}
  \end{center}
\end{figure}

Cette méthode est efficace pour reconnaitre le bout des membres et la tête, mais le reste des parties du corps est moins précis, notamment au niveau
des épaules où le point de la zone est très instable et peut se retrouver au niveau du torse. De plus la taille des zones dépend de la 
physionomie de la personne devant la Kinect. 
%Nous décidons donc de nous concentrer sur les parties que nous arrivons à détecter pour la 
%suite de nos traitements, c'est-à-dire les mains et la tête.

%\subsection{Calcule de descripteurs}
%d2
\subsection{SDK de la Kinect}
%récuperation du corps de la personne depuis une image kinect -> a partir des info de la kinect -> le mettre plutot dans les travaux réalisé
%labelisation en fonction de la distance du point avec le joint
Etant donné que nos résultats pour la segmentation du corps ne sont pas suffisemment précis pour la suite de nos traitements et par faute de
temps, nous avons décidé d'utiliser les outils fournis avec la Kinect pour continuer le projet. Grâce à la caméra de Microsoft, nous pouvons
récupérer le squelette de l'utilisateur dont les articulations sont labelisé avec le nom de la partie du corps humain à laquel elle appartient
(voir Fig. \ref{fig:kinect}.a). De plus, la Kinect nous permet de séparer les points qui appartiennent à l'utilisateur de ceux qui appartiennent
à l'environnement (voir Fig. \ref{fig:kinect}.b).\\

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[width=2cm]{image/kinectSkeleton.png} 
    \includegraphics[width=8cm]{image/seg1.PNG}
    \caption{a) Squelette fournit par la caméra Kinect et b) séparation du corps humain de l'environnement}
    \label{fig:kinect}
  \end{center}
\end{figure}

Grâce à ce squelette et au nuage de point nous pouvons segmenter le corps humain. Pour cela, pour chaque articulation nous définissons une zone
dont la taille est variable en fonction de l'articulation. Les points du nuage sont labelisé en fonction de leur distance avec les articulations.
Donc un point prend le label de l'articulation dont il est le plus proche.

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[height=4cm]{image/lab1.PNG} 
    \includegraphics[height=4cm]{image/lab2.PNG}
    \includegraphics[height=4cm]{image/lab3.PNG}
    \caption{Résultat obtenu avec la segmentation du corps humain via les outils de la Kinect}
  \end{center}
\end{figure}

Nous pouvons voir que comme nous l'attendions, le résultat de cette segmentation est bien meilleur puisque nous avons à notre disposition
beaucoup plus d'information qu'auparavant grâce au squelette de l'utilisateur. Même si cette segmentation n'est pas parfaite comme on peut
le voir dans la première image, elle reste suffisante pour nos futures traitement. En plus de la segmentation nous connaissons déjà le nom
des membres grâce aux labels des articulations, nous n'avons donc pas besoin de passer par une étape de reconnaissance des parties du
corps, car celle-ci a déjà été réalisé par les outils de la Kinect. Il ne reste plus qu'à supprimer le bruit présent dans les membres, les points
mal labeliser, grâce à la classe StatisticalOutlierRemoval que nous avons vu précédemment.

\subsection{Positionnement}
%icp, fpfh
%dire qu'il n'est pas possible d'utiliser la distance geodesic pour le positionnement a cause du temps et qu'on ne peut calculer la distance geodesic
%sur le mesh de remplacement
La dernière étape de cette première application est d'échanger le nuage de point d'un membre du corps par un modèle 3D représentant cette même partie
du corps. Cette partie est très complexe à cause de deux problème majeur. Tout d'abord, le type d'information n'est pas le même. Dans un cas nous avons
un nuage de point dont les points sont très concentrés, mais avec des parties occultés. De l'autre côté, nous avons un modèle 3D avec un nombre de point
inconnu et donc une concentration de point inconnu, et avec aucune zone occulté si nous prenons en concidération le maillage du modèle. Le second problème
est que le but recherché est de remplacer la partie du corps humain par quelque chose de plus improbable et étonnant comme une partie du corps d'un monstre,
d'un robot ou d'un corps dont la musculature est différentes.\\

Nous testons dans un premier temps l'algorithme le plus utilisé dans la littérature en terme de correspondance de modéle 3D. L'algorithme ICP\cite{ICP} est
disponible dans la librairie PCL\cite{PCL}. Après plusieurs tests sur différentes partie du corps, nous pouvons voir que l'algorithme ICP arrive à déterminer
la bonne translation si on compare les centroïdes des modèle 3D avec leur partie du corps correspondant. Cependant, ICP ne parvient pas à déterminer
l'orientation du modèle. Le problème vient du fait que les données ne sont pas les mêmes. Malgrès que les données soit différentes, la forme général
d'une partie du corps reste la même que ce soit un modèle ou un nuage de point, donc sa boîte englobante reste similaire également. Nous utilisons la méthode
de moment d'inertie de S. Ushakov disponible dans PCL pour déterminer l'orientation du nuage de point à partir de la matrice de covariance
(voir Fig. \ref{tab:modelMatching}).\\

\begin{figure}[!ht]
  \begin{center}
    \begin{tabular}{C{2cm}|c|c}
      modèle & position 1 & position 2 \\
      \hline
      pince de crabe (main gauche) & \includegraphics[height=4cm]{image/crabPlier1.PNG} & \includegraphics[height=4cm]{image/crabPlier2.PNG} \\
      \hline
      main robot (main gauche) & \includegraphics[height=4cm]{image/cyberHand1.PNG} & \includegraphics[height=4cm]{image/cyberHand2.PNG} \\
      \hline
      main cybord (main droite) & \includegraphics[height=4cm]{image/cyborgHand1.PNG} & \includegraphics[height=4cm]{image/cyborgHand2.PNG} \\
      \hline
      main de monstre (main droite) & \includegraphics[height=4cm]{image/monsterHand1.PNG} & \includegraphics[height=4cm]{image/monsterHand2.PNG} \\
      \hline
      tête cyborg & \includegraphics[height=4cm]{image/cyborgHead.PNG} &  \\
      \hline
    \end{tabular}
    \caption{Résultat de remplacement de partie du corps par des modèles 3D}
    \label{tab:modelMatching}
  \end{center}
\end{figure}

Nous pouvons voir sur les résultats de la correspondance de modéle qu'il y a deux problèmes importants. Le premier problème est celui de l'orientation
de certain modèle 3D. Dans la majorité des tests que nous avons effectué, il y a au moins deux axes sur lequels l'orientation est la bonne. La méthode 
permet de déterminer l'orientation, mais pas le sens, ce qui implique que dans certains cas l'un des axes soit tourné visuellement du mauvais côté.
Le second problème provient du non raccord du modèle avec le reste du nuage de point qui est très bien illustré dans l'exemple de la pince de crabe.
Pourtant dans chacun des cas la translation est juste, nous le vérifions en comparant la position du centroïde entre le modèle 3D et le nuage de point
(il existe juste un petit décalage sur la profondeur à cause des zones occultées dans le nuage de point). Ce décalage est du à une différence de ce qui est 
pris en compte comme étant une main par exemple. Dans le nuage de point, la zone considéré comme étant la main comporte la main et le poignet alors que 
dans le modèle 3D de la main de monstre le poignet n'est pas présent.\\

La mise en place d'une correspondance entre une nuage de point et un modèle 3D d'une partie du corps n'est pas suffisemment précise. Pour pallier
aux erreurs de l'application, nous avons envisagé de laisser la possibilité à l'utilisateur d'intéragir avec celle-ci. Le plus important est l'orientation
du modèle et nous savons que en cas d'erreur il faut effectuer une rotation du modèle de 180\degre sur l'un des trois axes. L'utilisateur aurai juste à 
sélectionner l'axe qui ne convient pas et l'application effectuerai la rotation seul. Maintenant que nous avons vu un cas particulier, nous allons pouvoir
partir sur une application plus généraliste et plus simple en réutilisant ce qui a été vu pour l'application sur le corps humain.  
