\subsection{Segmentation}
%recuperation d'un objet dans l'environnemnt -> interaction utilisateur
%dire que la création d'une base de connaissance est plus utile que pour le corps humain
La première étape lors de notre projet va être de segmenter les images que nous recevons de 
notre caméra. Les informations contenues dans une image 3D sont nombreuses et nous devons
déterminer les éléments important pour nos traitements. Dans notre scène,
nous avons besoin des objets proches ou du corps de la personne en face de la caméra, mais 
l'environnement autour des ces objets clés n'est pas important et doit être supprimer pour
gagner du temps lors de nos traitements en supprimant de l'information à traiter.
Une second segmentation est nécessaire pour le traitement du corps humain. Pour cette étape du projet,
nous devons segmenter le corps en plusieurs partie pour pouvoir par la suite les reconnaitres. Si cette
seconde segmentation n'est pas réalisé il ne nous sera pas possible de reconnaître les mains ou encore
la tête si nous ne savons délimité les parties du corps.  
 
\subsubsection{Scène intérieur}
De nombreux travaux ont été réalisé dans la segmentation d'image 2D avant que les caméras 3D ne soit
ouvert au grand public. Les premières méthode de segmentation reposaient sur la détection de contour
comme pour la méthode de P. Arbelaez et al\cite{2DSegmentation1}. Leur méthode repose sur le détecteur
de contour gPb qui est composé de d'un seuillage sur la luminance et sur la couleur et d'une détection
de texture. La fermeture des contours se fait ensuite en utilisant les superpixels. D'autres méthodes
2D utilise un simple seuillage en utilisant par exemple la méthode de N. Otsu\cite{Otsu} pour binariser
l'image et ainsi la segmenter.\\

%peut etre que l on peut rajouter des publi utilisant la depthmap
%voir si on sépare la depthmap et le nuage de point
Avec l'arrivé des caméras 3D de nombreuses recherche ont été effectué sur la segmentation d'image à partir
des information extraite de ce type de caméra. S.A.A Shah et al\cite{3DSegmentation1} utilisent les informations
de l'image de profondeur afin de calculer un vecteur sur chaque pixel. En applicant un seuillage sur la différence
des vecteurs ils obtiennent une segmentation de l'environnement qui leur permet de détecter des objets dans une pièce.
Il est possible à partir de l'image de profondeur de créer un nuage de point, ce qui permet d'obtenir les 
coordonnées 3D des points présents dans l'image de profondeur. Les informations qu'il est possible d'extraire
d'un nuage de point sont différentes et des méthodes de segmentation se sont développé autour de ces informations.\\

T. Rabbani et al\cite{pointCloudSegmentation} utilise les informations obtenus dans un nuage de point afin 
de calculer les normales de chaque point. Ils segmente ensuite l'image en comparant les normales et en appliquant
un seuillage sur cette comparaison. Si l'angle formé par les normales de deux points est super au seuil alors
les points appartiennent à deux régions différentes.

\subsubsection{Corps humain}
La segmentation du corps humain est un sujet très complexe, car contrairement au objet celui-ci bouge et adopte
des postures différentes. La méthode la plus souvent utilisé pour résoudre cette problématique est de déterminer
la posture de l'utilisateur et lorsque cette posture est connu il est facile de déterminer les différentes partie
du corps. Ces méthodes nécessitent d'avoir une base de connaissance contenant de nombreuses postures qui doivent
être segmenter et labelisé avec les différentes parties du corps. J. Shotton et al\cite{kinectSegmentation} ont
d'abord créé une base d'apprentissage en calculant un descripteur\footnote{Voir \ref{descriptor}}
et une technique d'apprentissage automatique appelé forêt d'arbres décisionnels\cite{randomDecisionForest}. 
Lorsque l'utilisateur bouge, le descripteur utilisé précédemment est recalculé sur l'image courante et le résultat 
est comparé au posture de la base d'apprentissage. La posture ayant une valeur proche du résultat calculé précédemment 
est la posture de l'utilisateur.

\subsection{Reconnaissance d'objets}
%FPFH
%SHOT
\subsubsection{Descripteur}
\label{descriptor}
\subsubsection{Apprentissave automatique}
%svm
%random forest
\subsubsection{Bag of word}

\subsection{Positionnement de modèle}
%moment d'inertie pour la position des membres
%PCA
